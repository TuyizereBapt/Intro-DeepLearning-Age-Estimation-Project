{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FinalProject-Conv&LSTM-Timit.ipynb","provenance":[],"collapsed_sections":["SDRjSg7qc5bQ","jj-plpr5c9j4","SVug45ODO1Yi","mWRRFh6IO5Uh","q2V85L4dPAzq","jEhjLNAVKWAc"],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"AcFpb37abZMe","executionInfo":{"status":"ok","timestamp":1607669453645,"user_tz":-120,"elapsed":3439,"user":{"displayName":"TUYIZERE Jean Baptiste","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXU_OkGDsaoMyU7EyzV-v6nMjACppcpbvTTS4QSA=s64","userId":"04729594738040986575"}}},"source":["import os\n","import time\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","# import audtorch\n","import torch\n","from torch import nn\n","from torch.nn.utils.rnn import *\n","import matplotlib.pyplot as plt"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mhg7W8RjWhBy","executionInfo":{"status":"ok","timestamp":1607127224856,"user_tz":-120,"elapsed":2052,"user":{"displayName":"asantewaa bremang","photoUrl":"","userId":"11817221182431494713"}},"outputId":"ab6e21ae-fde2-4d9e-ac1c-56fbf431ae78"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Sat Dec  5 00:13:43 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 455.45.01    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   49C    P0    35W / 250W |    897MiB / 16280MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"HmRDBxt6cQXW"},"source":["## Connecting GDrive"]},{"cell_type":"code","metadata":{"id":"zixhekm2cFsB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607669649146,"user_tz":-120,"elapsed":36664,"user":{"displayName":"TUYIZERE Jean Baptiste","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXU_OkGDsaoMyU7EyzV-v6nMjACppcpbvTTS4QSA=s64","userId":"04729594738040986575"}},"outputId":"3183ca84-d897-4a4c-b014-e790ee6dd6a4"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"77-eGH4zcJP6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607669651501,"user_tz":-120,"elapsed":2344,"user":{"displayName":"TUYIZERE Jean Baptiste","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXU_OkGDsaoMyU7EyzV-v6nMjACppcpbvTTS4QSA=s64","userId":"04729594738040986575"}},"outputId":"04fc200c-443a-4843-c5b6-a160c2106305"},"source":["%cd /content/gdrive/My\\ Drive/Colab/IDL_Final_Project  \n","# %cd /content/gdrive/My\\ Drive/IDL_Final_Project   "],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/gdrive/.shortcut-targets-by-id/1Sr9hCVVWERdsdT-sePtsjuVIxzvSrDI1/Colab/IDL_Final_Project\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"n6JKPNlJcSLF"},"source":["## Loading data"]},{"cell_type":"code","metadata":{"id":"GT36Pc_2cMHH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607669673060,"user_tz":-120,"elapsed":16324,"user":{"displayName":"TUYIZERE Jean Baptiste","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXU_OkGDsaoMyU7EyzV-v6nMjACppcpbvTTS4QSA=s64","userId":"04729594738040986575"}},"outputId":"c041e292-7483-4fe0-cac6-6cfb7fd9c82a"},"source":["train_data = np.load(\"train_data.npy\",allow_pickle=True)  \n","train_labels = np.load(\"train_labels.npy\",allow_pickle=True)\n","\n","test_data = np.load(\"test_data.npy\",allow_pickle=True)  \n","test_labels = np.load(\"test_labels.npy\",allow_pickle=True)\n","\n","# Labels columns: age, height, gender\n","# age: years, height: centimeters, gender: 1-male, 0-female\n","# train_labels[0]\n","# >> array([27.  ,  167.64,    0.  ])\n","print(len(train_data))\n","print(len(train_labels))\n","print(len(test_data))"],"execution_count":4,"outputs":[{"output_type":"stream","text":["4610\n","4610\n","1697\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"csPqibH6r4bQ"},"source":["# Shuffling data\n","train_indices = np.random.permutation(len(train_data))\n","train_data = train_data[train_indices]\n","train_labels = train_labels[train_indices]\n","\n","test_indices = np.random.permutation(len(test_data))\n","test_data = test_data[test_indices]\n","test_labels = test_labels[test_indices]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_cJZ2timCrQR","executionInfo":{"status":"ok","timestamp":1607475396929,"user_tz":-120,"elapsed":1450,"user":{"displayName":"TUYIZERE Jean Baptiste","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXU_OkGDsaoMyU7EyzV-v6nMjACppcpbvTTS4QSA=s64","userId":"04729594738040986575"}},"outputId":"e6870a3f-f058-4a62-ddd8-d1e886fa588b"},"source":["male_train_labels = train_labels[train_labels[:,-1] == 1]\n","m_tr_avg_age = male_train_labels[:,0].mean()\n","\n","female_train_labels = train_labels[train_labels[:,-1] == 0]\n","f_tr_avg_age = female_train_labels[:,0].mean()\n","\n","print(\"Female's avg age: \", f_tr_avg_age)\n","print(\"Male's avg age: \", m_tr_avg_age)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Female's avg age:  30.133333333333333\n","Male's avg age:  30.75153374233129\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"agPzi_p29ceR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607475403525,"user_tz":-120,"elapsed":1519,"user":{"displayName":"TUYIZERE Jean Baptiste","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXU_OkGDsaoMyU7EyzV-v6nMjACppcpbvTTS4QSA=s64","userId":"04729594738040986575"}},"outputId":"5ba83ecb-f9e2-4176-83da-f91eb2c615c3"},"source":["male_test_labels = test_labels[test_labels[:,-1] == 1]\n","m_test_avg_age = male_test_labels[:,0].mean()\n","\n","female_test_labels = test_labels[test_labels[:,-1] == 0]\n","f_test_avg_age = female_test_labels[:,0].mean()\n","\n","print(\"Female's avg age: \", m_test_avg_age)\n","print(\"Male's avg age: \", f_test_avg_age)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Female's avg age:  31.229609929078013\n","Male's avg age:  31.045694200351495\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Yb53SCATEjg9"},"source":["# Changing age to the average\n","# tr_labels = train_labels.copy()\n","\n","# for idx in range(tr_labels.shape[0]):\n","  \n","#   if tr_labels[idx, -1] == 1:\n","#     tr_labels[idx, 0] = m_avg\n","#   else:\n","#     tr_labels[idx, 0] = f_avg\n","\n","tes_labels = test_labels.copy()\n","for idx in range(tes_labels.shape[0]):\n","  \n","  if tes_labels[idx, -1] == 1:\n","    tes_labels[idx, 0] = m_tr_avg_age\n","  else:\n","    tes_labels[idx, 0] = f_tr_avg_age"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sI1lWf9afZFw"},"source":["Normalizing training Labels to have zero mean and unit standard deviation"]},{"cell_type":"code","metadata":{"id":"zZjLvz0WeShl"},"source":["# tr_labels[:,:-1] = (tr_labels[:,:-1] - tr_labels[:,:-1].mean(axis=0))/tr_labels[:,:-1].std(axis=0)\n","\n","# tes_labels[:,:-1] = (tes_labels[:,:-1] - tes_labels[:,:-1].mean(axis=0))/tes_labels[:,:-1].std(axis=0)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"428RLazdcfoB"},"source":["## Dataset"]},{"cell_type":"code","metadata":{"id":"Sovqxxc3ckXJ"},"source":["class CustomDataset(Dataset):\n","  def __init__(self,data,labels=None):\n","\n","    lens = [utter.shape[0] for utter in data]\n","    max_lens = max(lens)\n","\n","    pad_above = 0; pad_below = 0\n","    pad_left = 0; pad_right = 0\n","    \n","    self.X = []\n","\n","    for utter in data:\n","      utter = np.pad(utter, pad_width=((pad_above, max_lens-utter.shape[0]),(pad_left, pad_right)))\n","      utter = torch.from_numpy(utter)\n","      utter = utter.T  # (64, 336)\n","\n","      self.X.append(utter.type(torch.float32))\n","\n","    # self.X = [torch.from_numpy(d) for d in data]\n","\n","    if labels is not None:\n","      self.y = torch.from_numpy(labels) \n","  \n","  def __len__(self):\n","    return len(self.X)\n","\n","  def __getitem__(self,idx):\n","    X = self.X[idx]\n","\n","    if self.y is not None:\n","      y = self.y[idx]\n","\n","      return X, y\n","    else:\n","      return X, None"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IkyWu466czno"},"source":["## Dataloader"]},{"cell_type":"markdown","metadata":{"id":"SDRjSg7qc5bQ"},"source":["### Collate Function"]},{"cell_type":"code","metadata":{"id":"iGNYYQL6c1Sn"},"source":["def collate_fn(batch_data):\n","    inputs, targets = zip(*batch_data)\n","\n","    inp_lens = [seq.size(0) for seq in inputs]\n","\n","    inputs = [input.type(torch.float32) for input in inputs]     \n","\n","    padded_inputs = pad_sequence(inputs, batch_first=True)\n","    targets_cat = torch.cat(targets, 0).type(torch.float32)\n","\n","    return padded_inputs, inp_lens, targets_cat"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jj-plpr5c9j4"},"source":["### DataLoaders"]},{"cell_type":"code","metadata":{"id":"ZtRYgmFSdAh8"},"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# # Training\n","# batch_size = 128\n","\n","# train_dataset = CustomDataset(train_data,train_labels)\n","# train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size, \n","#                           num_workers=4,collate_fn=collate_fn,drop_last=True) \n","\n","# # Validation\n","# validation_dataset = CustomDataset(test_data, tes_labels)  #test_labels: age is the average age for corresponding to the gender in training data\n","# validation_loader = DataLoader(validation_dataset, shuffle=False, \n","#                                batch_size=batch_size, num_workers=4, \n","#                                collate_fn=collate_fn,drop_last=True)\n","\n","\n","# Training\n","batch_size = 64\n","\n","train_dataset = CustomDataset(train_data,train_labels)\n","train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size, \n","                          num_workers=4,drop_last=True) \n","\n","# Validation\n","val_dataset = CustomDataset(test_data, tes_labels)  #test_labels: age is the average age for corresponding to the gender in training data\n","validation_loader = DataLoader(val_dataset, shuffle=False,batch_size=batch_size, \n","                               num_workers=4, drop_last=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xthYz0eUP_aV"},"source":["# in_channels = 64\n","# out_channels = 128\n","# k_sz = 3 \n","\n","# cnn = nn.Conv1d(in_channels=in_channels, out_channels=out_channels, kernel_size=k_sz, stride=2, padding=0, bias=False)\n","# pool = nn.AvgPool1d(3, stride=2)\n","# linear = nn.Linear(out_channels , 64)\n","\n","# lstm = nn.LSTM(\n","#             input_size = 64,\n","#             hidden_size = 256,\n","#             num_layers = 2, \n","#             dropout = 0.3,\n","#             bidirectional = False,\n","#             batch_first = True\n","#         )\n","\n","# for inputs, labels in validation_loader:\n","#   inp = inputs\n","\n","#   print(\"in\",inp.size())\n","#   print(\"in labels\",labels.size())\n","\n","#   out = cnn(inp)\n","#   print(\"CNN out\", out.size())\n","\n","#   out = pool(out)\n","#   print(\"Pool out\", out.size())\n","\n","#   out = linear(out.permute(0, 2,1))\n","#   print(\"Linear out\", out.size())\n","\n","#   out, _ = lstm(out)\n","#   print(\"LSTM out\", out.size())\n","\n","#   break"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"67_E8V_GdT2k"},"source":["## Model"]},{"cell_type":"code","metadata":{"id":"T5qz0KRxdWJe"},"source":["class Model(nn.Module):\n","    def __init__(self, input_size, hidden_size, dropout, batch_size, layers=1, output_size=1, bd=False):\n","        super(Model, self).__init__()\n","\n","        self.num_layers = layers\n","        self.batch_size = batch_size\n","        self.hidden_size = hidden_size\n","\n","        self.num_d = 1  # Number of directions\n","\n","\n","        in_channels = input_size #64\n","        out_channels = 128\n","        k_sz = 3 \n","\n","        if bd:\n","          self.num_d = 2\n","\n","        self.cnn = nn.Conv1d(in_channels=in_channels, out_channels=out_channels, kernel_size=k_sz, stride=1, padding=0, bias=False)\n","        self.bn = nn.BatchNorm1d(out_channels)\n","        self.avg_pool = nn.AvgPool1d(3, stride=2)\n","        \n","        self.linear = nn.Linear(out_channels , 64)\n","\n","        self.lstm = nn.LSTM(\n","            input_size = 64,\n","            hidden_size = hidden_size,\n","            num_layers = layers, \n","            dropout = dropout,\n","            bidirectional = bd,\n","            batch_first = True\n","        )\n","        \n","        self.fc2 = nn.Linear(hidden_size * self.num_d, output_size)\n","\n","        self.init_weights()\n","    \n","    def forward(self, batch_data,lens,hidden=None): \n","  \n","        # ps = pack_padded_sequence(batch_data, batch_first=True, lengths=lens, enforce_sorted=False)\n","\n","        # Forward propagate LSTM\n","\n","        emb = self.cnn(batch_data)  # emb => (batch_size, out_channels, Lout)\n","        # emb = F.relu(self.bn(emb))\n","        emb = self.avg_pool(emb)   \n","\n","    \n","        out = self.linear(emb.permute(0, 2,1))\n","\n","\n","        # out, hidden = self.lstm(out)\n","        \n","        #out = out.permute(1,0,2) #asantewaa change\n","        #print(\"before lstm\",out.shape)#,hidden)\n","        if hidden is not None:\n","          out, hidden = self.lstm(out, hidden)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n","        else:\n","          out, hidden = self.lstm(out)\n","\n","        # out, out_lens = pad_packed_sequence(out, batch_first=True)\n","        #out = out.permute(1,0,2)\n","        #print(\"from lstm\",out.shape)\n","        # Decode the hidden state of the last time step\n","        last_time_step_out = out[:,-1] #out[-1]  # out[-1] is for taking output at the last time step\n","        # out = self.fc1(last_time_step_out)\n","        out = self.fc2(last_time_step_out)\n","\n","        return out.view(-1), hidden\n","\n","    def init_hidden(self):\n","        weight = next(self.parameters()).data\n","        hidden = (weight.new(self.num_layers * self.num_d, self.batch_size, self.hidden_size).zero_().to(device),\n","                    weight.new(self.num_layers * self.num_d, self.batch_size, self.hidden_size).zero_().to(device))\n","        return hidden\n","\n","    def init_weights(self):\n","      for name, param in self.lstm.named_parameters():\n","        if 'bias' in name:\n","          nn.init.constant_(param, 0.0)\n","        elif 'weight' in name:\n","          nn.init.xavier_normal_(param)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P6_ONz7aeiii"},"source":["## Training"]},{"cell_type":"markdown","metadata":{"id":"SVug45ODO1Yi"},"source":["### Validate"]},{"cell_type":"code","metadata":{"id":"owm40vpyelK4"},"source":["def validate(model,validation_loader):\n","  model.eval()\n","  running_loss_v = 0.0\n","  correct_v = 0\n","  total_v = 0\n","\n","  with torch.no_grad():\n","    # for batch_idx, (X, inp_len, y) in enumerate(validation_loader):\n","    for batch_idx, (X, y) in enumerate(validation_loader):\n","      inp_len = 0\n","\n","      X = X.to(device)\n","      y = y.to(device)\n","\n","      age_prediction, _ = model(X,inp_len)\n","\n","      loss = criterion(age_prediction,y[:,0])\n","\n","      preds = age_prediction.cpu().numpy()\n","\n","      # loss2 = criterion(height_prediction,y[:,1])\n","\n","      # loss = loss1 + loss2  # Adding for MTL\n","\n","      running_loss_v += loss.item()\n","\n","      # print('Batch val loss', loss.item())\n","      total_v += y.size(0)\n","\n","\n","      torch.cuda.empty_cache()\n","      del X; del y\n","      del age_prediction #; del height_prediction\n","      # del loss1; del loss2\n","      del loss\n","\n","\n","  avg_loss_v = running_loss_v / len(validation_loader)\n","\n","  return avg_loss_v"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mWRRFh6IO5Uh"},"source":["### Train method"]},{"cell_type":"code","metadata":{"id":"Cag-cQ95-59Q"},"source":["def train():\n","\n","  total_loss = []\n","  running_loss = 0.0\n","  total = 0\n","\n","  val_avg_loss = []\n","  train_avg_loss_list = []\n","\n","  for epoch in range(NUM_EPOCHS):\n","    print(\"EPOCH #\",epoch + 1)\n","    \n","    model.train()  # Re-enabling training\n","    \n","    start = time.time()\n","\n","    hidden = model.init_hidden() #asantewaa change\n","\n","    # for batch_idx, (X, inp_lens, y) in enumerate(train_loader):\n","    for batch_idx, (X, y) in enumerate(train_loader):\n","      \n","      inp_lens = 0\n","\n","      hidden = tuple([e.data for e in hidden])\n","\n","      optimizer.zero_grad()\n","\n","      X = X.to(device)\n","      y = y.to(device)\n","\n","      t0 = time.time()\n","      #print(\"shape of x\",X.shape)\n","\n","      age_prediction, h = model(X, inp_lens, hidden) #asantewaa change\n","      hidden = h\n","      \n","      loss = criterion(age_prediction,y[:,0])\n","\n","      running_loss += loss.item()\n","      total += y.size(0)\n","\n","\n","      if (batch_idx + 1) % 10 == 0 or (batch_idx + 1) == len(train_loader):\n","        print('[Batch {}]\\tLoss: {}'.format(batch_idx + 1, loss.item()))\n","        #print(age_prediction,y[:,0])\n","\n","      t1 = time.time()\n","\n","      loss.backward()\n","\n","      t2 = time.time()\n","      \n","      if batch_idx == 0 and epoch == 0:\n","        print(\"Model Prediction time: \", t1 - t0)\n","        print(\"Loss Backward computation time: \", (time.time() - t2))\n","\n","      optimizer.step()\n","      # scheduler.step()\n","      scheduler.step(loss)\n","\n","\n","      torch.cuda.empty_cache()\n","      del X; del y\n","      del age_prediction  #; del height_prediction\n","      # del loss1; del loss2\n","      del loss\n","\n","    train_avg_loss = running_loss / total\n","\n","    # Validating\n","    t0 = time.time()\n","    validation_avg_loss = validate(model,validation_loader)\n","    running_loss/= len(train_loader)\n","    total_loss.append(running_loss)\n","    train_avg_loss_list.append(train_avg_loss)\n","\n","    val_avg_loss.append(validation_avg_loss)\n","\n","    if epoch == 0:\n","      print(\"Validation time: \", (time.time() - t0))\n","      print(\"Epoch duration time: \", (time.time() - start))\n","      print(\"*\" * 30)\n","      print(\"\")\n","\n","    print('Epoch [%d] [train] loss: %.8f' %(epoch + 1, train_avg_loss))\n","    print('[running] loss: %.8f' % (running_loss))\n","    print('[valid] loss: %.8f' % (validation_avg_loss))\n","    print(\"-\" * 30)\n","\n","    if len(val_avg_loss) >= 2 and val_avg_loss[-1] > val_avg_loss[-2]:\n","      print(\"Stopped. Model started overfitting data\")\n","      break\n","\n","  return val_avg_loss"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q2V85L4dPAzq"},"source":["### main"]},{"cell_type":"code","metadata":{"id":"E-ga7dkIhKrH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607476156966,"user_tz":-120,"elapsed":156505,"user":{"displayName":"TUYIZERE Jean Baptiste","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXU_OkGDsaoMyU7EyzV-v6nMjACppcpbvTTS4QSA=s64","userId":"04729594738040986575"}},"outputId":"5e160db8-bf16-4b75-d518-6563ed9c469b"},"source":["NUM_EPOCHS = 20 #100\n","\n","learning_rate = 1e-01  # Best with ADAM: 1e-01\n","\n","input_size = 64\n","hidden_size = 256\n","dropout = 0.5\n","nlayers = 2\n","bidirectional = True#False\n","\n","model = Model(input_size,hidden_size,dropout, batch_size,layers=nlayers, bd=bidirectional)\n","\n","model.to(device)\n","\n","criterion = nn.L1Loss() #nn.MSELoss()\n","optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate, weight_decay=5e-06)\n","# optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate, momentum=0.9)\n","\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min',\n","    factor=0.1, patience=20, threshold=0.01, verbose=True)\n","\n","val_avg_loss = train()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["EPOCH # 1\n","Model Prediction time:  0.036441802978515625\n","Loss Backward computation time:  0.0002410411834716797\n","[Batch 10]\tLoss: 8.149078965187073\n","[Batch 20]\tLoss: 4.946771144866943\n","[Batch 30]\tLoss: 4.893670558929443\n","[Batch 40]\tLoss: 5.141988396644592\n","[Batch 50]\tLoss: 7.683287560939789\n","Epoch    57: reducing learning rate of group 0 to 1.0000e-02.\n","[Batch 60]\tLoss: 3.9995731711387634\n","[Batch 70]\tLoss: 5.5028835237026215\n","[Batch 72]\tLoss: 6.159053236246109\n","Validation time:  0.8028295040130615\n","Epoch duration time:  7.819829940795898\n","******************************\n","\n","Epoch [1] [train] loss: 0.10575596\n","[running] loss: 6.76838175\n","[valid] loss: 5.18993583\n","------------------------------\n","EPOCH # 2\n","Epoch    81: reducing learning rate of group 0 to 1.0000e-03.\n","[Batch 10]\tLoss: 5.805405139923096\n","[Batch 20]\tLoss: 6.791080117225647\n","[Batch 30]\tLoss: 5.059199750423431\n","Epoch   102: reducing learning rate of group 0 to 1.0000e-04.\n","[Batch 40]\tLoss: 5.276941627264023\n","[Batch 50]\tLoss: 4.578257858753204\n","Epoch   123: reducing learning rate of group 0 to 1.0000e-05.\n","[Batch 60]\tLoss: 6.176542669534683\n","[Batch 70]\tLoss: 3.8551429212093353\n","[Batch 72]\tLoss: 6.76135578751564\n","Epoch [2] [train] loss: 0.04243749\n","[running] loss: 5.43199889\n","[valid] loss: 4.35469047\n","------------------------------\n","EPOCH # 3\n","[Batch 10]\tLoss: 5.8967161774635315\n","[Batch 20]\tLoss: 5.666345089673996\n","[Batch 30]\tLoss: 5.097214192152023\n","Epoch   176: reducing learning rate of group 0 to 1.0000e-06.\n","[Batch 40]\tLoss: 3.9167940616607666\n","[Batch 50]\tLoss: 5.617553323507309\n","[Batch 60]\tLoss: 6.04444494843483\n","Epoch   208: reducing learning rate of group 0 to 1.0000e-07.\n","[Batch 70]\tLoss: 5.9131999015808105\n","[Batch 72]\tLoss: 5.657492399215698\n","Epoch [3] [train] loss: 0.02808141\n","[running] loss: 5.39163072\n","[valid] loss: 4.34103922\n","------------------------------\n","EPOCH # 4\n","[Batch 10]\tLoss: 4.346448302268982\n","Epoch   229: reducing learning rate of group 0 to 1.0000e-08.\n","[Batch 20]\tLoss: 4.667709857225418\n","[Batch 30]\tLoss: 5.891589432954788\n","[Batch 40]\tLoss: 5.562350392341614\n","[Batch 50]\tLoss: 4.843766510486603\n","[Batch 60]\tLoss: 4.727987140417099\n","[Batch 70]\tLoss: 5.858829617500305\n","[Batch 72]\tLoss: 5.712707847356796\n","Epoch [4] [train] loss: 0.02107973\n","[running] loss: 5.39641046\n","[valid] loss: 4.34101090\n","------------------------------\n","EPOCH # 5\n","[Batch 10]\tLoss: 5.435901492834091\n","[Batch 20]\tLoss: 4.528388142585754\n","[Batch 30]\tLoss: 6.27897834777832\n","[Batch 40]\tLoss: 6.003602862358093\n","[Batch 50]\tLoss: 5.4308339059352875\n","[Batch 60]\tLoss: 5.0950082540512085\n","[Batch 70]\tLoss: 4.830528229475021\n","[Batch 72]\tLoss: 5.792175203561783\n","Epoch [5] [train] loss: 0.01681665\n","[running] loss: 5.38132726\n","[valid] loss: 4.34100848\n","------------------------------\n","EPOCH # 6\n","[Batch 10]\tLoss: 4.841699779033661\n","[Batch 20]\tLoss: 4.075688064098358\n","[Batch 30]\tLoss: 5.126609742641449\n","[Batch 40]\tLoss: 6.607089072465897\n","[Batch 50]\tLoss: 5.042984485626221\n","[Batch 60]\tLoss: 6.457111150026321\n","[Batch 70]\tLoss: 5.485439777374268\n","[Batch 72]\tLoss: 6.174463629722595\n","Epoch [6] [train] loss: 0.01405216\n","[running] loss: 5.39602897\n","[valid] loss: 4.34100733\n","------------------------------\n","EPOCH # 7\n","[Batch 10]\tLoss: 6.1120694279670715\n","[Batch 20]\tLoss: 5.225401431322098\n","[Batch 30]\tLoss: 6.622971445322037\n","[Batch 40]\tLoss: 6.672604322433472\n","[Batch 50]\tLoss: 5.364098399877548\n","[Batch 60]\tLoss: 4.857961863279343\n","[Batch 70]\tLoss: 5.292585074901581\n","[Batch 72]\tLoss: 6.743505835533142\n","Epoch [7] [train] loss: 0.01202972\n","[running] loss: 5.38931546\n","[valid] loss: 4.34100424\n","------------------------------\n","EPOCH # 8\n","[Batch 10]\tLoss: 4.900625914335251\n","[Batch 20]\tLoss: 6.693627774715424\n","[Batch 30]\tLoss: 5.319719731807709\n","[Batch 40]\tLoss: 4.392427623271942\n","[Batch 50]\tLoss: 5.914478749036789\n","[Batch 60]\tLoss: 5.089791387319565\n","[Batch 70]\tLoss: 5.027972757816315\n","[Batch 72]\tLoss: 6.189997464418411\n","Epoch [8] [train] loss: 0.01051539\n","[running] loss: 5.38387905\n","[valid] loss: 4.34100296\n","------------------------------\n","EPOCH # 9\n","[Batch 10]\tLoss: 5.976466655731201\n","[Batch 20]\tLoss: 5.776869058609009\n","[Batch 30]\tLoss: 5.098627179861069\n","[Batch 40]\tLoss: 4.779985815286636\n","[Batch 50]\tLoss: 5.772384494543076\n","[Batch 60]\tLoss: 5.007788717746735\n","[Batch 70]\tLoss: 4.965800315141678\n","[Batch 72]\tLoss: 5.467665791511536\n","Epoch [9] [train] loss: 0.00935533\n","[running] loss: 5.38867112\n","[valid] loss: 4.34100039\n","------------------------------\n","EPOCH # 10\n","[Batch 10]\tLoss: 5.098056256771088\n","[Batch 20]\tLoss: 5.928755342960358\n","[Batch 30]\tLoss: 5.630989670753479\n","[Batch 40]\tLoss: 7.234924286603928\n","[Batch 50]\tLoss: 5.347123712301254\n","[Batch 60]\tLoss: 5.8188731372356415\n","[Batch 70]\tLoss: 4.195175111293793\n","[Batch 72]\tLoss: 6.710141569375992\n","Epoch [10] [train] loss: 0.00842743\n","[running] loss: 5.39355646\n","[valid] loss: 4.34099711\n","------------------------------\n","EPOCH # 11\n","[Batch 10]\tLoss: 4.86479127407074\n","[Batch 20]\tLoss: 5.099454313516617\n","[Batch 30]\tLoss: 4.5384023785591125\n","[Batch 40]\tLoss: 5.696051269769669\n","[Batch 50]\tLoss: 4.6362956166267395\n","[Batch 60]\tLoss: 4.864980101585388\n","[Batch 70]\tLoss: 5.933459937572479\n","[Batch 72]\tLoss: 3.926608085632324\n","Epoch [11] [train] loss: 0.00765773\n","[running] loss: 5.39104494\n","[valid] loss: 4.34099525\n","------------------------------\n","EPOCH # 12\n","[Batch 10]\tLoss: 5.929428905248642\n","[Batch 20]\tLoss: 4.477188438177109\n","[Batch 30]\tLoss: 6.604000240564346\n","[Batch 40]\tLoss: 6.4924591183662415\n","[Batch 50]\tLoss: 6.0546020567417145\n","[Batch 60]\tLoss: 3.9913210272789\n","[Batch 70]\tLoss: 5.466873407363892\n","[Batch 72]\tLoss: 4.9889169335365295\n","Epoch [12] [train] loss: 0.00701839\n","[running] loss: 5.39012201\n","[valid] loss: 4.34098975\n","------------------------------\n","EPOCH # 13\n","[Batch 10]\tLoss: 5.2537049651145935\n","[Batch 20]\tLoss: 6.726209223270416\n","[Batch 30]\tLoss: 6.906996458768845\n","[Batch 40]\tLoss: 7.524465888738632\n","[Batch 50]\tLoss: 5.3917176723480225\n","[Batch 60]\tLoss: 3.7006737887859344\n","[Batch 70]\tLoss: 5.795872926712036\n","[Batch 72]\tLoss: 5.8387371599674225\n","Epoch [13] [train] loss: 0.00647093\n","[running] loss: 5.38381318\n","[valid] loss: 4.34098357\n","------------------------------\n","EPOCH # 14\n","[Batch 10]\tLoss: 5.724027574062347\n","[Batch 20]\tLoss: 5.94302561879158\n","[Batch 30]\tLoss: 5.419261276721954\n","[Batch 40]\tLoss: 4.577796757221222\n","[Batch 50]\tLoss: 4.257197231054306\n","[Batch 60]\tLoss: 4.765373080968857\n","[Batch 70]\tLoss: 5.466163098812103\n","[Batch 72]\tLoss: 5.1486386358737946\n","Epoch [14] [train] loss: 0.00601437\n","[running] loss: 5.38887602\n","[valid] loss: 4.34098052\n","------------------------------\n","EPOCH # 15\n","[Batch 10]\tLoss: 5.155015617609024\n","[Batch 20]\tLoss: 5.7695611119270325\n","[Batch 30]\tLoss: 3.509705275297165\n","[Batch 40]\tLoss: 5.196335941553116\n","[Batch 50]\tLoss: 5.07101646065712\n","[Batch 60]\tLoss: 5.423883885145187\n","[Batch 70]\tLoss: 5.793181747198105\n","[Batch 72]\tLoss: 4.981720298528671\n","Epoch [15] [train] loss: 0.00562782\n","[running] loss: 5.40271167\n","[valid] loss: 4.34097550\n","------------------------------\n","EPOCH # 16\n","[Batch 10]\tLoss: 5.33181968331337\n","[Batch 20]\tLoss: 4.360093981027603\n","[Batch 30]\tLoss: 6.601973831653595\n","[Batch 40]\tLoss: 5.481325477361679\n","[Batch 50]\tLoss: 5.721961051225662\n","[Batch 60]\tLoss: 4.81727659702301\n","[Batch 70]\tLoss: 5.871043533086777\n","[Batch 72]\tLoss: 4.349059224128723\n","Epoch [16] [train] loss: 0.00526994\n","[running] loss: 5.39641526\n","[valid] loss: 4.34097103\n","------------------------------\n","EPOCH # 17\n","[Batch 10]\tLoss: 5.397373616695404\n","[Batch 20]\tLoss: 5.0529278218746185\n","[Batch 30]\tLoss: 4.94257926940918\n","[Batch 40]\tLoss: 6.255556434392929\n","[Batch 50]\tLoss: 4.256385564804077\n","[Batch 60]\tLoss: 6.097351461648941\n","[Batch 70]\tLoss: 5.037676393985748\n","[Batch 72]\tLoss: 5.343267500400543\n","Epoch [17] [train] loss: 0.00493845\n","[running] loss: 5.37303140\n","[valid] loss: 4.34096807\n","------------------------------\n","EPOCH # 18\n","[Batch 10]\tLoss: 6.6516015231609344\n","[Batch 20]\tLoss: 5.375723898410797\n","[Batch 30]\tLoss: 4.038781672716141\n","[Batch 40]\tLoss: 5.235371857881546\n","[Batch 50]\tLoss: 3.868556499481201\n","[Batch 60]\tLoss: 6.059874266386032\n","[Batch 70]\tLoss: 6.2264683842659\n","[Batch 72]\tLoss: 4.332574188709259\n","Epoch [18] [train] loss: 0.00467840\n","[running] loss: 5.38951918\n","[valid] loss: 4.34096166\n","------------------------------\n","EPOCH # 19\n","[Batch 10]\tLoss: 5.433237314224243\n","[Batch 20]\tLoss: 4.964011490345001\n","[Batch 30]\tLoss: 4.750501304864883\n","[Batch 40]\tLoss: 5.414918035268784\n","[Batch 50]\tLoss: 6.759134441614151\n","[Batch 60]\tLoss: 5.161237061023712\n","[Batch 70]\tLoss: 4.1402807533741\n","[Batch 72]\tLoss: 6.2080667316913605\n","Epoch [19] [train] loss: 0.00443250\n","[running] loss: 5.38991646\n","[valid] loss: 4.34095651\n","------------------------------\n","EPOCH # 20\n","[Batch 10]\tLoss: 5.44268661737442\n","[Batch 20]\tLoss: 4.780934423208237\n","[Batch 30]\tLoss: 5.939481556415558\n","[Batch 40]\tLoss: 5.51488396525383\n","[Batch 50]\tLoss: 4.055358648300171\n","[Batch 60]\tLoss: 5.225646913051605\n","[Batch 70]\tLoss: 6.018879145383835\n","[Batch 72]\tLoss: 3.859991818666458\n","Epoch [20] [train] loss: 0.00421807\n","[running] loss: 5.39913396\n","[valid] loss: 4.34095139\n","------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JbsmBvCB4QXF"},"source":["from time import time\n","torch.save({\n","            'model_state_dict': model.state_dict(),\n","            'optimizer_state_dict': optimizer.state_dict(),\n","            'lr': learning_rate,\n","            'hidden_size': hidden_size,\n","            'dropout': dropout,\n","            'layers': nlayers,\n","            'val_loss':val_avg_loss[-1] \n","        }, \"Model_avg_age_\"+str(time())+\".model\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YheBja-oQdTh","colab":{"base_uri":"https://localhost:8080/","height":312},"executionInfo":{"status":"ok","timestamp":1607477120580,"user_tz":-120,"elapsed":5740,"user":{"displayName":"TUYIZERE Jean Baptiste","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXU_OkGDsaoMyU7EyzV-v6nMjACppcpbvTTS4QSA=s64","userId":"04729594738040986575"}},"outputId":"ca1813dc-1fae-4892-8c8a-c9ec8e510bcc"},"source":["fig = plt.gcf()\n","\n","plt.plot(list(range(1,len(val_avg_loss) + 1)), val_avg_loss)\n","plt.xlabel(\"Epochs\")\n","plt.ylabel('Loss')\n","plt.title('Validation loss')\n","\n","plt.show()\n","plt.draw()\n","fig.savefig('avg_age_loss_lr1_{}_data_{}.png'.format(learning_rate,len(train_labels)), dpi=100)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"rKJt_h8gjOXr"},"source":["## L1 Loss and L2 Loss on Test data"]},{"cell_type":"code","metadata":{"id":"Phu_Oue8jNnz"},"source":["model.eval()\n","\n","predictions = []\n","targets = []\n","\n","with torch.no_grad():\n","  for batch_idx, (X, y) in enumerate(validation_loader):\n","\n","    X = X.to(device)\n","\n","    output, hidden = model(X,0)\n","\n","    pred = output.cpu().numpy()\n","\n","    predictions.extend(pred.tolist())\n","    targets.extend(y[:,[0,-1]].numpy().tolist())\n","\n","    torch.cuda.empty_cache()\n","    del X; del hidden\n","    del output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uZ6cPFku-Asc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1607476212587,"user_tz":-120,"elapsed":1806,"user":{"displayName":"TUYIZERE Jean Baptiste","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXU_OkGDsaoMyU7EyzV-v6nMjACppcpbvTTS4QSA=s64","userId":"04729594738040986575"}},"outputId":"052f2269-8d8f-4e06-b429-17fa89cfb861"},"source":["predictions = torch.Tensor(predictions)\n","targets = torch.Tensor(targets)\n","\n","mae_loss = nn.L1Loss() \n","mse_loss = nn.MSELoss()\n","\n","l1 = mae_loss(predictions, targets[:,0])\n","l2 = mse_loss(predictions, targets[:,0])\n","\n","print(\"MAE: \", l1.item())\n","print(\"MSE: \", l2.item())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["MAE:  4.340951442718506\n","MSE:  18.929119110107422\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Fnji5wbl--aC"},"source":["### MALE"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TwCEy10a8i8v","executionInfo":{"status":"ok","timestamp":1607476212587,"user_tz":-120,"elapsed":1800,"user":{"displayName":"TUYIZERE Jean Baptiste","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXU_OkGDsaoMyU7EyzV-v6nMjACppcpbvTTS4QSA=s64","userId":"04729594738040986575"}},"outputId":"46894531-f0e9-4461-b116-e38473e17168"},"source":["index = targets[:,1] == 1\n","\n","l1 = mae_loss(predictions[index], targets[index][:,0])\n","l2 = mse_loss(predictions[index], targets[index][:,0])\n","\n","print(\"Avg: \", predictions[index].numpy().mean())\n","print(\"MAE: \", l1.item())\n","print(\"MSE: \", l2.item())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Avg:  26.203756\n","MAE:  4.547776699066162\n","MSE:  20.68248176574707\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"AZGL0kMw_B7l"},"source":["### FEMALE"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MTkB4Ihj_Fau","executionInfo":{"status":"ok","timestamp":1607476212588,"user_tz":-120,"elapsed":1794,"user":{"displayName":"TUYIZERE Jean Baptiste","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXU_OkGDsaoMyU7EyzV-v6nMjACppcpbvTTS4QSA=s64","userId":"04729594738040986575"}},"outputId":"36e373a8-148b-4997-da38-ad89b52aa781"},"source":["index = targets[:,1] == 0\n","\n","l1 = mae_loss(predictions[index], targets[index][:,0])\n","l2 = mse_loss(predictions[index], targets[index][:,0])\n","\n","print(\"Avg: \", predictions[index].numpy().mean())\n","print(\"MAE: \", l1.item())\n","print(\"MSE: \", l2.item())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Avg:  26.203434\n","MAE:  3.9298996925354004\n","MSE:  15.444428443908691\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jEhjLNAVKWAc"},"source":["## Losses with Actual Test labels"]},{"cell_type":"code","metadata":{"id":"xMxTCR0zKklZ"},"source":["validation_dataset = CustomDataset(test_data, test_labels)#test_labels\n","test_loader = DataLoader(validation_dataset, shuffle=False, \n","                               batch_size=batch_size, num_workers=4)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P0f15vs0KcMz"},"source":["model.eval()\n","\n","predictions = []\n","targets = []\n","\n","with torch.no_grad():\n","  for batch_idx, (X, y) in enumerate(test_loader):\n","\n","    X = X.to(device)\n","\n","    output, hidden = model(X,0)\n","\n","    pred = output.cpu().numpy()\n","\n","    predictions.extend(pred.tolist())\n","    targets.extend(y[:,[0,-1]].numpy().tolist())\n","\n","    torch.cuda.empty_cache()\n","    del X; del hidden\n","    del output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ghPfrAlgUt14","executionInfo":{"status":"ok","timestamp":1607476259011,"user_tz":-120,"elapsed":2405,"user":{"displayName":"TUYIZERE Jean Baptiste","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXU_OkGDsaoMyU7EyzV-v6nMjACppcpbvTTS4QSA=s64","userId":"04729594738040986575"}},"outputId":"2b5c2a1c-6995-45ed-bb25-6cad8bd132f8"},"source":["print(min(predictions))\n","print(max(predictions))\n","# predictions"],"execution_count":null,"outputs":[{"output_type":"stream","text":["26.021648406982422\n","26.354368209838867\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bKvwmSggJCTL","executionInfo":{"status":"ok","timestamp":1607476259011,"user_tz":-120,"elapsed":2400,"user":{"displayName":"TUYIZERE Jean Baptiste","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXU_OkGDsaoMyU7EyzV-v6nMjACppcpbvTTS4QSA=s64","userId":"04729594738040986575"}},"outputId":"f05fa98c-64b5-42b6-edd4-c7f388943a74"},"source":["print(min(targets))\n","print(max(targets))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[22.0, 0.0]\n","[68.0, 0.0]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Jskd7PWdKy35"},"source":["predictions = torch.Tensor(predictions)\n","targets = torch.Tensor(targets)\n","\n","mae_loss = nn.L1Loss() \n","mse_loss = nn.MSELoss()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"go80y2elK4QI"},"source":["### Male"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ao2aMx1iK6IT","executionInfo":{"status":"ok","timestamp":1607476259012,"user_tz":-120,"elapsed":2391,"user":{"displayName":"TUYIZERE Jean Baptiste","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXU_OkGDsaoMyU7EyzV-v6nMjACppcpbvTTS4QSA=s64","userId":"04729594738040986575"}},"outputId":"e07341e1-4134-41cf-f86e-9bfaced991ff"},"source":["index = targets[:,1] == 1\n","\n","l1 = mae_loss(predictions[index], targets[index][:,0])\n","l2 = mse_loss(np.round(predictions[index]), targets[index][:,0])\n","print(targets[index][:,0])\n","print(np.round(predictions[index]))\n","#print(\"Avg: \", predictions[index].numpy().mean())\n","print(\"MAE: \", l1.item())\n","print(\"MSE: \", l2.item())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([28., 33., 25.,  ..., 29., 45., 27.])\n","tensor([26., 26., 26.,  ..., 26., 26., 26.])\n","MAE:  5.85436487197876\n","MSE:  92.42819213867188\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9ns6sl-IK7J6"},"source":["### Female"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mFlfwUW3K9eJ","executionInfo":{"status":"ok","timestamp":1607476259013,"user_tz":-120,"elapsed":2386,"user":{"displayName":"TUYIZERE Jean Baptiste","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjXU_OkGDsaoMyU7EyzV-v6nMjACppcpbvTTS4QSA=s64","userId":"04729594738040986575"}},"outputId":"06cd5d91-6f16-4622-f749-a69191ebe7d9"},"source":["index = targets[:,1] == 0\n","\n","l1 = mae_loss(predictions[index], targets[index][:,0])\n","l2 = mse_loss(predictions[index], targets[index][:,0])\n","\n","#print(\"Avg: \", predictions[index].numpy().mean())\n","print(\"MAE: \", l1.item())\n","print(\"MSE: \", l2.item())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["MAE:  6.250591278076172\n","MSE:  105.10982513427734\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lf6YLTHC_B5D"},"source":[""],"execution_count":null,"outputs":[]}]}